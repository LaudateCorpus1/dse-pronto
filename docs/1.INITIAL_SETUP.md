# Initial Setup

There's a bunch of **one-time** setup you'll need to do before you start baking AMIs or deploying clusters.

### 1. Setup - AWS CLI

You'll need an [awscli profile](https://docs.aws.amazon.com/cli/latest/userguide/cli-chap-configure.html) configured with
Admin permissions as your base credentials.  This Admin profile will be used for the first few "Setup" steps.  After that,
Packer and Terraform will [assume](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles_use_permissions-to-switch.html)
roles with **scoped permissions**.

The base Admin profile can be based on a user (with permanent keys) or a role (with temp keys and a session token).  Your
choice, they just need to be valid/refreshed whenever you're trying to do something.

### 2. Setup - VPC

**Packer** will need a VPC with at least 1 public subnet to bake AMIs.  The default VPC that comes with any AWS account
will work, but remember:  to deploy in another account, you'll need to [share the AMI](https://packer.io/docs/builders/amazon-ebs.html#ami_users)
with that account.  To deploy in another region, you'll have to [copy the AMI](https://packer.io/docs/builders/amazon-ebs.html#ami_regions)
to that region.

**Terraform** will deploy all of the resources in this repo into a VPC.  The default VPC in your account is _not_ set up
properly; by default, you're missing private subnets and NAT Gateways, your default RTB only has implicit subnet associations,
and none of your subnets have a Name tag.
* If you don't have a VPC and would like Terraform to **manage one for you**, it will be created later during the deployment
  step.  For now, move on to setup step 3 below.
* If you **do** have a VPC, it must conform to a typical
[public/private subnet architecture](https://docs.aws.amazon.com/vpc/latest/userguide/VPC_Scenario2.html)
including NAT Gateways and an Internet Gateway.
  * Before moving on, validate your VPC with the [validate-vpc.sh](../validate-vpc.sh) script.
  * Note that this script will define routes where appropriate, if necessary.  Therefore, the profile (`-p`) you provide
    must have the ability to administer RTB settings.
```
$ ./validate-vpc.sh
Usage:
  validate-vpc.sh
    -p : [Required] AWS profile with Admin access to the target VPC
    -r : [Required] region of the target VPC
    -v : [Required] target VPC ID
    -i : name prefix for public subnets in ingress layer (default: 'Ingress')
    -d : name prefix for private subnets in DB layer (default: 'Data')
```

### 2. Setup - No, Really

**HEY!  DID YOU VALIDATE YOUR VPC?  GO BACK AND VALIDATE YOUR VPC.**

All kinds of weird things can happen if you try to deploy in an invalid VPC.

### 3. Setup - Config Profile

Pick an account name and cluster name.  Create a new configuration profile with the [create-configuration.sh](../create-configuration.sh)
script.
* If you have a **validated** VPC to use, **do not** provide the `-x` option.
* Otherwise, specify `-x` for a Terraform-managed VPC, which will be created later.
```
$ ./create-configuration.sh
Usage:
  create-configuration.sh
    -a : [Required] account name (e.g. "my-account")
    -v : [Required] vpc name (e.g. "primary-vpc" or "west-vpc")
    -c : [Required] cluster name (e.g. "dse-cluster" or "storage-cluster")
    -x : if specified, allow terraform to manage my vpc (default: false)"
```
After running, you'll have a few variables to fill in.  Follow the instructions when the script finishes.
* The params in [variables.yaml](../configurations/default-account/variables.yaml) prefixed with `PACKER_` are for AMI
  baking; the params prefixed with `TERRAFORM_` are for deployment.
  * If you want to bake AMIs in a pre-existing VPC (e.g. the default VPC), you can do that.  Just make sure the PACKER
    vars are all set to point there.  Once the AMI is baked, it can be deployed into another VPC, or even another account.
    The instructions are set up to be run in this order (setup, bake AMI, deploy stuff).
  * On the other hand, if you want to use Terraform to deploy a VPC, then bake AMIs _in that VPC_, you'll be doing things
    in a slightly different order:
    1. **First, finish all the setup steps on this page.**
    2. Then, skip ahead to the [deployment steps](3.TERRAFORM.md) and run the `account` and `vpc` layers.
    3. Now fill in the PACKER vars in [variables.yaml](../configurations/default-account/variables.yaml), aiming them at
       your new, Terraform-managed VPC.
    4. Finally, backtrack to the [AMI baking steps](2.PACKER.md) and proceed as normal.
* You can ignore variables in **opscenter.tfvars** for now, until you're ready to start working on OpsCenter.

### 4. Setup - OpsCenter (optional)

If you'll be using OpsCenter, you should follow the same instructions above to create another configuration profile for a
[separate storage cluster](https://docs.datastax.com/en/opscenter/6.5/opsc/configure/opscStoringCollectionDataDifferentCluster_t.html).
* This can use the same account name (`-a`) and be deployed in the same account, but it should have a different cluster name (`-c`).

### 5. Setup - State Bucket

Create an s3 bucket for Terraform [state files](https://www.terraform.io/docs/state/remote.html) and artifacts in the
target account.
* Note that all s3 buckets need to have [globally unique names](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingBucket.html).
```
$ aws s3 mb s3://${bucket_name} --profile ${profile} --region ${region}
```
* **Note:** it's best to be explicit about region with your `mb` (make bucket) command, just in case your defaults aren't
configured as you intend.
  * The region should match where you plan to deploy your DSE resources.
* Remember to set this bucket name as `TERRAFORM_STATE_BUCKET` in your [variables.yaml](../configurations/default-account/variables.yaml).
* The next step will create a `terraform-role` with access to the bucket.

### 6. Setup - Roles

Create roles in your account (for Packer and Terraform to use) with the [init-roles.sh](../init-roles.sh) script:
```
$ ./init-roles.sh
Usage:
  init-roles.sh
    -p : [Required] AWS profile with Admin access to IAM in the target account
    -a : [Required] account name
```
* This script will create IAM roles and policies.  Therefore, the profile you provide (`-p`) must have the ability to
  administer IAM resources in the target account.
* The profile specified (`-p`) will also be used as the Principal for AssumeRole policies on these roles.
  * The profile can point to a role or a user, as long as the credentials are valid.
  * You can modify the AssumeRole policy to add new trust relationships (e.g. the instance profile for your Jenkins server).
* **Note** that if your _AMI baking_ account and target _deployment_ account are different, they'll both need the roles,
  so you should run `init-roles.sh` in both accounts.  Just create awscli profiles with Admin access to each account, and
  run the script twice (with different `-p` options).
  * `packer-role` is only needed in the AMI baking account, `terraform-role` is only needed in your target deployment
    account.  They'll both be created, but you can delete the roles that aren't needed if you so choose.

### 7. Setup - SSH Keys

Create an SSH key for Ansible (and collect your own key as well) with the [init-ansible-key.sh](../core-components/scripts/ssh/init-ansible-key.sh)
script:
* The `-u` and `-n` options should point to public SSH keys (i.e. `~/.ssh/id_rsa.pub`).
  * These can also both be configured in the [variables.yaml](../configurations/default-account/variables.yaml) for your
    account.
* If the Ansible key doesn't exist at the configured location, a new one will be created.
* If the User key (your personal key) doesn't exist, the script will exit with an error.
```
$ ./core-components/scripts/ssh/init-ansible-key.sh
Usage:
  init-ansible-key.sh
    -a : [Required] account name
    -v : [Required] vpc name
    -c : [Required] cluster name
    -u : [Optional] path to existing user public key (.pub)
    -n : [Optional] path to existing ansible public key (.pub)
    -f : [Optional] force re-creation of user-keys file
```

### 8. Setup - Passwords

Your Cassandra cluster will require passwords for the keystore, truststore, and  Cassandra DB user.  Run the script
[init-secrets.sh](../core-components/scripts/secrets/init-secrets.sh) before deploying for the first time.  This script
gathers passwords interactively, then stores them in the tfstate bucket; it will use the profile `TERRAFORM_AWS_PROFILE`
configured in your [cluster.tfvars](../configuration/default-account/default-cluster/cluster.tfvars) file to access the
bucket.
```
$ ./core-components/scripts/secrets/init-secrets.sh
Usage:
  init-secrets.sh
    -a : [Required] account name
    -v : [Required] vpc name
    -c : [Required] cluster name
    -d : [Optional] delete s3 secrets file, if it exists, then generate a new one
    -x : [Optional] verify existence of s3 secrets file, then exit
```

### 9. Setup - SSL cert

If you DO NOT have an SSL cert, you can skip this.

If you have an SSL cert, upload like so:
```
aws s3 cp ./certs/ca-key s3://${BUCKET}/${account_name}/${vpc_name}/${cluster}/files/certs/ca-key --region ${region}
aws s3 cp ./certs/ca-cert s3://${BUCKET}/${account_name}/${vpc_name}/${cluster}/files/certs/ca-cert  --region ${region}
aws s3 cp ./keystores/server-truststore.jks s3://${BUCKET}/${account_name}/${vpc_name}/${cluster}/files/keystores/server-truststore.jks --region ${region}
```
**Ensure that it is named properly.**